{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "from skimage.transform import rotate\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images\n",
    "train_data = train_data.reshape(-1,28,28,1)\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта штука бьёт на пары двойным циклом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_train(X, y, z, predictor):\n",
    "    pairs = []\n",
    "    \n",
    "    C0_mask, C1_mask = np.all(y == 0, axis=1), np.all(y == 1, axis=1)        \n",
    "    C0, C1 = X[C0_mask], X[C1_mask]\n",
    "    C0_vectors, C1_vectors = predictor(C0), predictor(C1)\n",
    "    C0, C1, C0_vectors, C1_vectors = list(map(lambda x: list(x), [C0, C1, C0_vectors, C1_vectors]))\n",
    "        \n",
    "    z0,z1 = z[C0_mask].reshape(-1), z[C1_mask].reshape(-1)\n",
    "    z0, z1 = list(z0), list(z1)\n",
    "        \n",
    "    while len(C0) > 0 and len(C1) > 0:\n",
    "        clear_output()\n",
    "        print(len(C0),' remain')\n",
    "        x0_index = 0 # будем подбираем пару для нулевого элемента C0\n",
    "        norm = np.linalg.norm(np.array(C1_vectors) - C0_vectors[0], axis=1)\n",
    "        x1_index = np.argmin(norm) # ему сгодится такая пара\n",
    "\n",
    "        new_pair = [C0[x0_index], C1[x1_index]]\n",
    "        pairs.append(new_pair) # присобачиваем полученную пару к pairs\n",
    "\n",
    "        del C0[x0_index]\n",
    "        del C1[x1_index]\n",
    "        del C0_vectors[x0_index]\n",
    "        del C1_vectors[x1_index]\n",
    "        del z0[x0_index]\n",
    "        del z1[x1_index]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем Cnn\n",
    "Второй метод отвечает за пересчёт вероятностей и соответствующих констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cnn(Model):\n",
    "    def __init__(self):\n",
    "  \n",
    "        def weighted_loss(constants):\n",
    "            def loss(y_true, y_pred):\n",
    "                return K.mean(constants * K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "            return loss\n",
    "\n",
    "        main_input = Input(shape=[28,28,1], name='input')\n",
    "        constants = Input(shape=[1], name='constants')\n",
    "\n",
    "        x = Conv2D(32, (3, 3), activation='relu')(main_input)\n",
    "        x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        output = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "        super().__init__(inputs=[main_input, constants], outputs=[output])\n",
    "        \n",
    "        self.compile(loss=weighted_loss(constants),\n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        y_ = K.placeholder([None, 1])\n",
    "        y_pred = self(inputs=[main_input,constants])\n",
    "        simple_loss = K.binary_crossentropy(output=y_pred, target=y_)\n",
    "        self.grads = K.function([main_input,constants, y_], K.gradients(simple_loss, self.weights))\n",
    "        \n",
    "        self.probs = None\n",
    "        self.consts = None\n",
    "        \n",
    "    def recompute_probs_and_consts(self):\n",
    "\n",
    "        def get_G(pair):\n",
    "            def l2_norm_of_list_of_arrays(list_of_arrays):\n",
    "                output = np.concatenate([elem.flatten() for elem in list_of_arrays])\n",
    "                output = output.reshape(-1)\n",
    "                return np.linalg.norm(output)\n",
    "            \n",
    "            def grads_on_pair(pair):\n",
    "                return self.grads([pair.reshape(-1,28,28,1),\n",
    "                                np.array([1,1]).reshape(-1,1),\n",
    "                                np.array([0,1]).reshape(-1,1)])\n",
    "            return l2_norm_of_list_of_arrays(grads_on_pair(pair))\n",
    "\n",
    "        self.probs = np.array([get_G(pair) + 1e-8 for pair in PAIRS], dtype='float64')\n",
    "        self.probs = self.probs / self.probs.sum()\n",
    "        self.probs = np.clip(self.probs, a_min=(1 / len(PAIRS))/50, a_max=(1 / len(PAIRS))*50)\n",
    "        self.probs = self.probs / self.probs.sum()\n",
    "\n",
    "        self.consts = (1 / len(PAIRS)) * (1 / self.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим, какие повороты не приводят к недо/переобучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pm 3 \\deg$, ничего не выучиваем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D0 = [rotate(img, np.random.normal(loc=-3, scale=5), order=0) for img in train_data]\n",
    "D1 = [rotate(img, np.random.normal(loc=3, scale=5) , order=0) for img in train_data]\n",
    "X = np.append(D0, D1, axis=0)\n",
    "y = np.append( np.zeros([len(D0),1]), np.ones([len(D1),1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88000 samples, validate on 22000 samples\n",
      "Epoch 1/5\n",
      "88000/88000 [==============================] - 90s 1ms/step - loss: 0.6056 - acc: 0.6645 - val_loss: 0.7109 - val_acc: 0.4922\n",
      "Epoch 2/5\n",
      "88000/88000 [==============================] - 90s 1ms/step - loss: 0.5556 - acc: 0.7164 - val_loss: 0.7494 - val_acc: 0.4484\n",
      "Epoch 3/5\n",
      "88000/88000 [==============================] - 56s 637us/step - loss: 0.5452 - acc: 0.7261 - val_loss: 0.8323 - val_acc: 0.4314\n",
      "Epoch 4/5\n",
      "88000/88000 [==============================] - 78s 885us/step - loss: 0.5390 - acc: 0.7288 - val_loss: 0.7492 - val_acc: 0.4569\n",
      "Epoch 5/5\n",
      "88000/88000 [==============================] - 85s 967us/step - loss: 0.5334 - acc: 0.7311 - val_loss: 0.7642 - val_acc: 0.4397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e346b8be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_3 = Cnn()\n",
    "cnn_3.fit([X, np.ones([len(X), 1])], y, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pm 5 \\deg$, что-то выучиваем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D0 = [rotate(img, np.random.normal(loc=-5, scale=5), order=0) for img in train_data]\n",
    "D1 = [rotate(img, np.random.normal(loc=5, scale=5) , order=0) for img in train_data]\n",
    "X = np.append(D0, D1, axis=0)\n",
    "y = np.append( np.zeros([len(D0),1]), np.ones([len(D1),1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88000 samples, validate on 22000 samples\n",
      "Epoch 1/3\n",
      "88000/88000 [==============================] - 86s 978us/step - loss: 0.4587 - acc: 0.7720 - val_loss: 0.5346 - val_acc: 0.6780\n",
      "Epoch 2/3\n",
      "88000/88000 [==============================] - 86s 978us/step - loss: 0.3869 - acc: 0.8222 - val_loss: 0.5305 - val_acc: 0.6652\n",
      "Epoch 3/3\n",
      "88000/88000 [==============================] - 88s 1000us/step - loss: 0.3775 - acc: 0.8266 - val_loss: 0.5541 - val_acc: 0.6668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e43110630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_5 = Cnn()\n",
    "cnn_5.fit([X, np.ones([len(X), 1])], y, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pm 15 \\deg$, слишком много всего выучиваем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D0 = [rotate(img, np.random.normal(loc=-15, scale=5), order=0) for img in train_data]\n",
    "D1 = [rotate(img, np.random.normal(loc=15, scale=5) , order=0) for img in train_data]\n",
    "X = np.append(D0, D1, axis=0)\n",
    "y = np.append( np.zeros([len(D0),1]), np.ones([len(D1),1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88000 samples, validate on 22000 samples\n",
      "Epoch 1/3\n",
      "88000/88000 [==============================] - 87s 988us/step - loss: 0.1072 - acc: 0.9553 - val_loss: 0.0291 - val_acc: 0.9879\n",
      "Epoch 2/3\n",
      "88000/88000 [==============================] - 86s 979us/step - loss: 0.0224 - acc: 0.9915 - val_loss: 0.0257 - val_acc: 0.9908\n",
      "Epoch 3/3\n",
      "88000/88000 [==============================] - 87s 992us/step - loss: 0.0164 - acc: 0.9936 - val_loss: 0.0181 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e34447ef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_15 = Cnn()\n",
    "cnn_15.fit([X, np.ones([len(X), 1])], y, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "так что в дальнейшем будем работать с поворотами на $\\pm5 \\deg$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравним uniform сэмплинг и smart сэмплинг \n",
    "Определим два сэмплера для сэмплинга пар:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_SHAPE = [-1, 28, 28, 1]\n",
    "def generate_uniform(pairs, batch_size=512):\n",
    "    while True:\n",
    "        inds = np.random.choice(len(pairs), size=(batch_size,))\n",
    "        current_x = pairs[inds]\n",
    "        current_y = np.array([[0,1] for _ in current_x])\n",
    "        current_x = current_x.reshape(*DATA_SHAPE)\n",
    "        current_y = current_y.reshape(-1,1)\n",
    "        yield {'input':current_x, 'constants':np.ones(current_y.shape)}, {'output':current_y}\n",
    "\n",
    "def generate_smart(pairs, probs, consts, batch_size=512):\n",
    "    while True:\n",
    "        inds = np.random.choice(len(pairs), size=[batch_size], p=probs)\n",
    "        current_x = pairs[inds]\n",
    "        current_y_ = np.array([[0,1] for _ in current_x])\n",
    "        current_c = np.array([[consts[i], consts[i]] for i in range(len(pairs))])[inds]\n",
    "        current_x = current_x.reshape(*DATA_SHAPE)\n",
    "        current_y_ = current_y_.reshape(-1,1)\n",
    "        current_c = current_c.reshape(-1,1)\n",
    "        yield {'input':current_x, 'constants':current_c}, {'output':current_y_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "датасет для сравнения ($30*2$к картинок)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  remain\n"
     ]
    }
   ],
   "source": [
    "D0 = [rotate(img, np.random.normal(loc=-5, scale=5), order=0) for img in train_data[:30000]]\n",
    "D1 = [rotate(img, np.random.normal(loc=5, scale=5) , order=0) for img in train_data[:30000]]\n",
    "X = np.append(D0, D1, axis=0)\n",
    "y = np.append( np.zeros([len(D0),1]), np.ones([len(D1),1]), axis=0)\n",
    "\n",
    "# Наконец побьём на пары:\n",
    "PAIRS = create_train(X, y , np.ones(len(y)), lambda x: x.reshape(-1,28*28))\n",
    "PAIRS = np.array(PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_uniform = Cnn()\n",
    "cnn_uniform.save_weights('weights')\n",
    "cnn_smart = Cnn()\n",
    "cnn_smart.load_weights('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем измерять лосс на трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "uniform_losses = []\n",
    "for _ in range(50):\n",
    "    clear_output()\n",
    "    print(_)\n",
    "    cnn_uniform.fit_generator(generate_uniform(PAIRS, batch_size=64),\n",
    "                            steps_per_epoch=100, epochs=1, verbose=False)\n",
    "    loss = cnn_uniform.evaluate([X, np.ones([len(X),1])], y, batch_size=128, verbose=False)[0]\n",
    "    uniform_losses.append(loss)\n",
    "    \n",
    "    \n",
    "smart_losses = []    \n",
    "for _ in range(50):\n",
    "    clear_output()\n",
    "    print(_)\n",
    "    if _ < 10:\n",
    "        cnn_smart.fit_generator(generate_uniform(PAIRS, batch_size=64),\n",
    "                            steps_per_epoch=100, epochs=1, verbose=False)\n",
    "    else:\n",
    "        if _ % 5 == 0:cnn_smart.recompute_probs_and_consts()\n",
    "        cnn_smart.fit_generator(generate_smart(PAIRS, cnn_smart.probs, cnn_smart.consts, batch_size=64),\n",
    "                                steps_per_epoch=100, epochs=1, verbose=False)    \n",
    "    loss = cnn_smart.evaluate([X, np.ones([len(X),1])], y, batch_size=128, verbose=False)[0]\n",
    "    smart_losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не наблюдаем преимуществ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nahlN/EopVcto4ldKqVrm/wFAOqd50nFcrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0cc9fa61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(uniform_losses)\n",
    "plt.plot(smart_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим, как влияет на переобучение софтплюс+l2рег"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cnn_softplus(Model):\n",
    "    def __init__(self):\n",
    "  \n",
    "        def weighted_loss(constants):\n",
    "            def loss(y_true, y_pred):\n",
    "                return K.mean(constants * K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "            return loss\n",
    "\n",
    "        main_input = Input(shape=[28,28,1], name='input')\n",
    "        constants = Input(shape=[1], name='constants')\n",
    "\n",
    "        x = Conv2D(32, (3, 3), activation='softplus', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(main_input)\n",
    "        x = Conv2D(32, (3, 3), activation='softplus', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='softplus', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='softplus', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='softplus', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "        output = Dense(1, activation='sigmoid', name='output', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "\n",
    "        super().__init__(inputs=[main_input, constants], outputs=[output])\n",
    "        \n",
    "        self.compile(loss=weighted_loss(constants),\n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        y_ = K.placeholder([None, 1])\n",
    "        y_pred = self(inputs=[main_input,constants])\n",
    "        simple_loss = K.binary_crossentropy(output=y_pred, target=y_)\n",
    "        self.grads = K.function([main_input,constants, y_], K.gradients(simple_loss, self.weights))\n",
    "        \n",
    "        self.probs = None\n",
    "        self.consts = None\n",
    "        \n",
    "    def recompute_probs_and_consts(self):\n",
    "\n",
    "        def get_G(pair):\n",
    "            def l2_norm_of_list_of_arrays(list_of_arrays):\n",
    "                output = np.concatenate([elem.flatten() for elem in list_of_arrays])\n",
    "                output = output.reshape(-1)\n",
    "                return np.linalg.norm(output)\n",
    "            \n",
    "            def grads_on_pair(pair):\n",
    "                return self.grads([pair.reshape(-1,28,28,1),\n",
    "                                np.array([1,1]).reshape(-1,1),\n",
    "                                np.array([0,1]).reshape(-1,1)])\n",
    "            return l2_norm_of_list_of_arrays(grads_on_pair(pair))\n",
    "\n",
    "        self.probs = np.array([get_G(pair) + 1e-8 for pair in PAIRS], dtype='float64')\n",
    "        self.probs = self.probs / self.probs.sum()\n",
    "        self.probs = np.clip(self.probs, a_min=(1 / len(PAIRS))/50, a_max=(1 / len(PAIRS))*50)\n",
    "        self.probs = self.probs / self.probs.sum()\n",
    "\n",
    "        self.consts = (1 / len(PAIRS)) * (1 / self.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pm 3 \\deg$, оверфит никуда не исчез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "D0 = [rotate(img, np.random.normal(loc=-3, scale=5), order=0) for img in train_data]\n",
    "D1 = [rotate(img, np.random.normal(loc=3, scale=5) , order=0) for img in train_data]\n",
    "X = np.append(D0, D1, axis=0)\n",
    "y = np.append( np.zeros([len(D0),1]), np.ones([len(D1),1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88000 samples, validate on 22000 samples\n",
      "Epoch 1/3\n",
      "88000/88000 [==============================] - 54s 612us/step - loss: 0.8294 - acc: 0.6224 - val_loss: 0.8999 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "88000/88000 [==============================] - 51s 576us/step - loss: 0.6724 - acc: 0.6246 - val_loss: 0.9583 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "88000/88000 [==============================] - 53s 600us/step - loss: 0.6684 - acc: 0.6250 - val_loss: 0.9809 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0cd94995f8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_softplus_3 = Cnn_softplus()\n",
    "cnn_softplus_3.fit([X, np.ones([len(X), 1])], y, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pm 5 \\deg$, оверфит никуда не исчез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D0 = [rotate(img, np.random.normal(loc=-5, scale=5), order=0) for img in train_data]\n",
    "D1 = [rotate(img, np.random.normal(loc=5, scale=5) , order=0) for img in train_data]\n",
    "X = np.append(D0, D1, axis=0)\n",
    "y = np.append( np.zeros([len(D0),1]), np.ones([len(D1),1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88000 samples, validate on 22000 samples\n",
      "Epoch 1/3\n",
      "88000/88000 [==============================] - 54s 616us/step - loss: 0.8163 - acc: 0.6232 - val_loss: 1.2001 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "88000/88000 [==============================] - 52s 590us/step - loss: 0.6708 - acc: 0.6250 - val_loss: 1.0481 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "88000/88000 [==============================] - 50s 569us/step - loss: 0.6681 - acc: 0.6250 - val_loss: 1.0190 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0cd8825fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_softplus_5 = Cnn_softplus()\n",
    "cnn_softplus_5.fit([X, np.ones([len(X), 1])], y, epochs=3, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
